# Self Service Dashboard AI

> **AI-powered Self Service Dashboard with PygWalker integration and Ollama-based intelligent dashboard generation**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Node.js](https://img.shields.io/badge/Node.js-16%2B-green)](https://nodejs.org/)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org/)
[![React](https://img.shields.io/badge/React-18-blue)](https://reactjs.org/)
[![Ollama](https://img.shields.io/badge/Ollama-Ready-purple)](https://ollama.ai/)

## ğŸš€ Quick Start

### One-Command Setup

```bash
# Clone the repository
git clone <your-repo-url>
cd SelfServiceDashboard-TM

# One-command setup
./setup.sh

# Install Ollama (interactive)
./scripts/install-ollama.sh

# Start development environment
./scripts/start-development.sh

# Open http://localhost:3000
```

## âœ¨ Features

### ğŸ¤– AI-Powered Dashboard Generation
- **Natural Language to Dashboard**: Describe what you want, AI creates it
- **Ollama Integration**: Local LLM for privacy and speed
- **Streamlit Dashboards**: Interactive, professional dashboards
- **Real-time Generation**: Watch your ideas come to life

### ğŸ“Š Interactive Analytics
- **PygWalker Integration**: Drag-and-drop data visualization
- **Multiple Data Sources**: Excel files, REST APIs, databases
- **Terminal Manager Optimized**: Built for operational data
- **Real-time Performance**: No timeouts, smooth interactions

### ğŸ”§ Developer Friendly
- **Zero Configuration**: Works out of the box
- **Hot Reload**: All services support development mode
- **Comprehensive Scripts**: Health checks, deployment, reset
- **Cross-Platform**: macOS, Linux, Windows (WSL)

## ğŸ“ Project Structure

```
SelfServiceDashboard-TM/
â”œâ”€â”€ setup.sh                     # ğŸ¯ One-command setup
â”œâ”€â”€ package.json                 # ğŸ“¦ Workspace configuration
â”œâ”€â”€ .env.example                 # ğŸ”§ Environment template
â”œâ”€â”€ docker-compose.yml           # ğŸ³ Optional Docker setup
â”‚
â”œâ”€â”€ frontend/                    # âš›ï¸ React Frontend
â”‚   â”œâ”€â”€ src/components/
â”‚   â”‚   â”œâ”€â”€ AIDashboardGenerator.js  # ğŸ¤– AI dashboard component
â”‚   â”‚   â””â”€â”€ LoadingStates.js         # ğŸ”„ Shared loading components
â”‚   â””â”€â”€ src/StandaloneChart.js       # ğŸ“Š Main visualization component
â”‚
â”œâ”€â”€ ai-backend/                  # ğŸ§  AI Backend (Python/Flask)
â”‚   â”œâ”€â”€ app.py                   # ğŸŒ Flask server
â”‚   â”œâ”€â”€ config.py                # âš™ï¸ Configuration management
â”‚   â”œâ”€â”€ requirements.txt         # ğŸ“‹ Python dependencies
â”‚   â”œâ”€â”€ install.sh              # ğŸ”§ Auto setup script
â”‚   â””â”€â”€ test_connection.py      # ğŸ” Ollama connection test
â”‚
â”œâ”€â”€ simple-backend/              # ğŸ”§ Simple Backend (Node.js)
â”‚   â””â”€â”€ (existing backend)       # ğŸ“¡ REST API endpoints
â”‚
â”œâ”€â”€ scripts/                     # ğŸ› ï¸ Management Scripts
â”‚   â”œâ”€â”€ start-development.sh     # ğŸš€ Start dev environment
â”‚   â”œâ”€â”€ start-production.sh      # ğŸ­ Start production mode
â”‚   â”œâ”€â”€ health-check.sh          # ğŸ” System health verification
â”‚   â”œâ”€â”€ install-ollama.sh        # ğŸ¦™ Ollama installation helper
â”‚   â””â”€â”€ reset-project.sh         # ğŸ”„ Clean project reset
â”‚
â”œâ”€â”€ docs/                        # ğŸ“š Documentation
â”‚   â”œâ”€â”€ SETUP.md                # ğŸ“‹ Detailed setup guide
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md       # ğŸ”§ Common issues & solutions
â”‚   â””â”€â”€ API.md                  # ğŸ“– AI backend API docs
â”‚
â””â”€â”€ generated-dashboards/        # ğŸ“Š Runtime generated dashboards
```

## ğŸ”§ Requirements

### System Requirements
- **Node.js** 16+ and npm 8+
- **Python** 3.8+ and pip3
- **Git** (recommended)
- **Ollama** (for AI features)

### Ports Used
- `3000` - Frontend (React)
- `5246` - Simple Backend (Node.js)
- `5247` - AI Backend (Python/Flask)
- `8501+` - Generated Streamlit dashboards
- `11434` - Ollama (if installed)

## ğŸ“– Documentation

- **[Setup Guide](docs/SETUP.md)** - Detailed installation and configuration
- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions
- **[API Documentation](docs/API.md)** - AI backend API reference

## ğŸ› ï¸ Available Scripts

### Development
```bash
npm run start              # Start development environment
npm run health            # Run health checks
./scripts/health-check.sh  # Detailed system health check
```

### Production
```bash
npm run start:prod        # Start production environment
npm run build:frontend    # Build frontend for production
```

### Maintenance
```bash
npm run reset             # Reset project (interactive)
./scripts/reset-project.sh --full    # Full reset
./scripts/reset-project.sh --quick   # Quick reset
```

### AI Backend
```bash
cd ai-backend
./install.sh             # Setup Python environment
./test_connection.py     # Test Ollama connection
python app.py            # Start AI backend directly
```

## ğŸ¤– AI Dashboard Examples

### Natural Language Prompts
```
"Create a sales performance dashboard with regional comparisons"
"Build an operational efficiency dashboard with KPIs and uptime metrics"
"Generate a financial overview with profit margins and cost analysis"
"Show fuel volume analysis with environmental impact metrics"
```

### Generated Features
- **Interactive Charts**: Plotly-powered visualizations
- **Real-time Data**: Live connection to your data sources
- **Professional Styling**: Terminal Manager branding
- **Export Options**: Multiple formats supported
- **Responsive Design**: Works on all devices

## ğŸ” Health Monitoring

The project includes comprehensive health monitoring:

```bash
# Quick health check
./scripts/health-check.sh

# Development mode check
./scripts/health-check.sh --dev-mode

# Setup mode check (during installation)
./scripts/health-check.sh --setup-mode
```

**Monitors:**
- âœ… System requirements (Node.js, Python, etc.)
- âœ… Project structure and files
- âœ… Environment setup (virtual envs, dependencies)
- âœ… Ollama installation and connectivity
- âœ… Port availability
- âœ… Service health (in dev/prod mode)

## ğŸ³ Docker Support

Optional Docker setup for containerized deployment:

```bash
# Start with Docker Compose
docker-compose up

# Development with hot reload
docker-compose -f docker-compose.dev.yml up
```

## ğŸ”’ Environment Variables

Copy `.env.example` to `.env` and customize:

```bash
# AI Backend Configuration
OLLAMA_URL=http://localhost:11434
AI_BACKEND_PORT=5247
OLLAMA_MODEL=llama3

# Frontend Configuration
REACT_APP_AI_BACKEND_URL=http://localhost:5247

# Development Configuration
NODE_ENV=development
LOG_LEVEL=info
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `./scripts/health-check.sh`
5. Commit changes: `git commit -m 'Add amazing feature'`
6. Push to branch: `git push origin feature/amazing-feature`
7. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Issues**: Report bugs or request features in [GitHub Issues](../../issues)
- **Documentation**: Check [docs/](docs/) for detailed guides
- **Health Check**: Run `./scripts/health-check.sh` for diagnostics

## ğŸ™ Acknowledgments

- **PygWalker** - Drag-and-drop visualization engine
- **Ollama** - Local LLM infrastructure
- **Streamlit** - Dashboard generation framework
- **React** - Frontend framework
- **Flask** - Backend API framework

---

**ğŸ¯ Built for Terminal Manager Operations | ğŸš€ Powered by AI | ğŸ’» Ready for Production**